{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1fFYdu3OQA3"
      },
      "source": [
        "# üéØ CaseGenius Enhanced: AI Case Study Generator with Ambiguity Resolution\n",
        "\n",
        "**New Feature:** Intelligent ambiguity detection and interactive clarification\n",
        "\n",
        "**Flow:**\n",
        "1. Enter case brief\n",
        "2. AI detects ambiguities\n",
        "3. Configure which questions to ask (max 3)\n",
        "4. Answer questions\n",
        "5. Generate comprehensive case study\n",
        "\n",
        "**Time:** 10-15 minutes | **Cost:** ~$4-5\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import subprocess, json\n",
        "import os, subprocess, json, time, re\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Local configuration (NO env variables)\n",
        "# ---------------------------\n",
        "LLM_MODE: str = 'gemini'                 # 'mock' | 'ollama' | 'gemini'\n",
        "OLLAMA_MODEL: str = 'llama3'             # local model name for Ollama\n",
        "GEMINI_API_KEY: str = 'API_KEY'   # <-- put your API key here\n",
        "GEMINI_MODEL: str = 'gemini-2.5-flash'   # recommended fast, balanced model\n",
        "\n",
        "# Toggle: use the official SDK (google.generativeai) or fall back to raw REST\n",
        "USE_GOOGLE_GENERATIVEAI_SDK: bool = True\n",
        "\n",
        "class LLMAdapter:\n",
        "    def __init__(self, mode: str):\n",
        "        self.mode = mode\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        if self.mode == 'mock':\n",
        "            return '[MOCK ANSWER] ' + prompt[:300]\n",
        "\n",
        "        if self.mode == 'ollama':\n",
        "            try:\n",
        "                r = subprocess.run(\n",
        "                    ['ollama', 'run', OLLAMA_MODEL, prompt],\n",
        "                    capture_output=True, text=True\n",
        "                )\n",
        "                return r.stdout.strip() or r.stderr.strip() or '[OLLAMA EMPTY]'\n",
        "            except Exception as e:\n",
        "                return '[OLLAMA ERROR] ' + str(e)\n",
        "\n",
        "        if self.mode == 'gemini':\n",
        "            # --- Preferred: google.generativeai SDK (works well in Colab/Jupyter) ---\n",
        "            if USE_GOOGLE_GENERATIVEAI_SDK:\n",
        "                try:\n",
        "                    import google.generativeai as genai\n",
        "                    genai.configure(api_key=GEMINI_API_KEY)   # explicit local key\n",
        "                    model = genai.GenerativeModel(GEMINI_MODEL)\n",
        "                    response = model.generate_content(prompt)\n",
        "                    return getattr(response, 'text', None) or '[GEMINI EMPTY]'\n",
        "                except Exception as sdk_err:\n",
        "                    # Fall back to REST if SDK not installed or import fails\n",
        "                    try:\n",
        "                        import requests\n",
        "                        url = f\"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}\"\n",
        "                        payload = {\n",
        "                            \"contents\": [\n",
        "                                {\"role\": \"user\", \"parts\": [{\"text\": prompt}]}\n",
        "                            ]\n",
        "                        }\n",
        "                        r = requests.post(url, json=payload, timeout=30)\n",
        "                        r.raise_for_status()\n",
        "                        data = r.json()\n",
        "                        try:\n",
        "                            return data[\"candidates\"][0][\"content\"][\"parts\"][0].get(\"text\", \"\") or json.dumps(data)[:800]\n",
        "                        except Exception:\n",
        "                            return json.dumps(data)[:800]\n",
        "                    except Exception as rest_err:\n",
        "                        return f\"[GEMINI REST ERROR] {rest_err} | [SDK ERROR] {sdk_err}\"\n",
        "\n",
        "            # --- Alternative: Raw REST only ---\n",
        "            else:\n",
        "                try:\n",
        "                    import requests\n",
        "                    if not GEMINI_API_KEY or GEMINI_API_KEY == 'PASTE_YOUR_KEY':\n",
        "                        return '[GEMINI CONFIG ERROR] Provide a valid GEMINI_API_KEY (local variable)'\n",
        "\n",
        "                    url = f\"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}\"\n",
        "                    payload = {\n",
        "                        \"contents\": [\n",
        "                            {\"role\": \"user\", \"parts\": [{\"text\": prompt}]}\n",
        "                        ]\n",
        "                    }\n",
        "                    resp = requests.post(url, json=payload, timeout=30)\n",
        "                    resp.raise_for_status()\n",
        "                    data = resp.json()\n",
        "                    try:\n",
        "                        return data[\"candidates\"][0][\"content\"][\"parts\"][0].get(\"text\", \"\") or json.dumps(data)[:800]\n",
        "                    except Exception:\n",
        "                        return json.dumps(data)[:800]\n",
        "                except Exception as e:\n",
        "                    return '[GEMINI REST ERROR] ' + str(e)\n",
        "\n",
        "        return '[UNKNOWN MODE]'\n",
        "\n",
        "# ---------------------------\n",
        "# Usage in Jupyter\n",
        "# ---------------------------\n",
        "llm = LLMAdapter(LLM_MODE)\n",
        "print('LLM_MODE =', LLM_MODE)\n",
        "print(llm.generate(\"Explain how AI works in a few words\"))"
      ],
      "metadata": {
        "id": "vnKVnBGyevU0",
        "outputId": "9dc4f85a-ae78-4a31-f137-33307a282d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM_MODE = gemini\n",
            "Learns from data patterns to predict or decide.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CASE_BRIEF = \"\"\"\n",
        "Create a comprehensive case study for a sub-brand launch.\n",
        "\n",
        "Company: L'Or√©al\n",
        "\n",
        "Analysis Required:\n",
        "1. CapEx & OpEx comparison with competitors\n",
        "2. Market modeling and sizing\n",
        "3. P&L projections\n",
        "4. Business Canvas\n",
        "5. Competitor Analysis\n",
        "6. Market gap identification\n",
        "\n",
        "Timeline: Launch in the next fiscal year.\n",
        "Target market: High-growth segments.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Case brief loaded\")\n"
      ],
      "metadata": {
        "id": "rAOPs9boaGMD",
        "outputId": "362ce128-5852-47e1-ee0c-9d96ebf0990e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Case brief loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AmbiguityDetector:\n",
        "    def detect(self, brief: str):\n",
        "        print(\"üîç Detecting ambiguities...\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Analyze the following case brief and identify ambiguities.\n",
        "\n",
        "Return ONLY a JSON array.\n",
        "Each item must have:\n",
        "- term\n",
        "- category\n",
        "- question\n",
        "- options (3‚Äì4)\n",
        "- importance (HIGH/MEDIUM/LOW)\n",
        "\n",
        "Case Brief:\n",
        "{brief}\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = llm.generate(prompt)\n",
        "            match = re.search(r\"\\[.*\\]\", response, re.DOTALL)\n",
        "            return json.loads(match.group()) if match else []\n",
        "        except Exception as e:\n",
        "            print(\"‚ùå Ambiguity detection failed:\", e)\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "iUa9Vt67eRjk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = AmbiguityDetector()\n",
        "detected_ambiguities = detector.detect(CASE_BRIEF)\n",
        "\n",
        "print(f\"\\nFound {len(detected_ambiguities)} ambiguities:\\n\")\n",
        "for i, amb in enumerate(detected_ambiguities, 1):\n",
        "    print(f\"{i}. [{amb['importance']}] {amb['term']}\")"
      ],
      "metadata": {
        "id": "1HCeJB9ZezYa",
        "outputId": "6fab9909-008c-4862-f82c-c1ac195d1011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Detecting ambiguities...\n",
            "\n",
            "Found 11 ambiguities:\n",
            "\n",
            "1. [HIGH] Sub-brand definition\n",
            "2. [MEDIUM] Comprehensive case study deliverables\n",
            "3. [HIGH] Competitors for CapEx & OpEx\n",
            "4. [MEDIUM] CapEx & OpEx comparison detail\n",
            "5. [HIGH] Market for modeling and sizing\n",
            "6. [HIGH] P&L projection details\n",
            "7. [LOW] Business Canvas format\n",
            "8. [HIGH] Competitors for Competitor Analysis\n",
            "9. [MEDIUM] Market gap criteria\n",
            "10. [HIGH] Launch definition and timeline\n",
            "11. [HIGH] High-growth segments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detector = AmbiguityDetector()\n",
        "detected_ambiguities = detector.detect(CASE_BRIEF)\n",
        "\n",
        "print(f\"\\nFound {len(detected_ambiguities)} ambiguities:\\n\")\n",
        "for i, amb in enumerate(detected_ambiguities, 1):\n",
        "    print(f\"{i}. [{amb['importance']}] {amb['term']}\")\n"
      ],
      "metadata": {
        "id": "0hdnLPNafBLQ",
        "outputId": "63368f48-4063-4437-f8ab-b73047e9ffa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Detecting ambiguities...\n",
            "\n",
            "Found 9 ambiguities:\n",
            "\n",
            "1. [HIGH] sub-brand launch\n",
            "2. [HIGH] comprehensive case study\n",
            "3. [HIGH] competitors (CapEx & OpEx comparison)\n",
            "4. [MEDIUM] CapEx & OpEx comparison\n",
            "5. [MEDIUM] P&L projections\n",
            "6. [HIGH] next fiscal year\n",
            "7. [HIGH] High-growth segments\n",
            "8. [MEDIUM] Market gap identification\n",
            "9. [MEDIUM] Competitor Analysis (point 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTIONS_TO_ASK = [\n",
        "    i for i, amb in enumerate(detected_ambiguities)\n",
        "    if amb[\"importance\"] == \"HIGH\"\n",
        "][:3]\n",
        "\n",
        "print(\"\\nQuestions selected:\")\n",
        "for idx in QUESTIONS_TO_ASK:\n",
        "    print(\"-\", detected_ambiguities[idx][\"term\"])\n"
      ],
      "metadata": {
        "id": "ULSX72IRfBN7",
        "outputId": "c43a147b-74b6-4945-890d-76938d51d19d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Questions selected:\n",
            "- sub-brand launch\n",
            "- comprehensive case study\n",
            "- competitors (CapEx & OpEx comparison)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_answers = {}\n",
        "\n",
        "for idx in QUESTIONS_TO_ASK:\n",
        "    amb = detected_ambiguities[idx]\n",
        "\n",
        "    print(\"\\n‚ùì\", amb[\"question\"])\n",
        "    for i, opt in enumerate(amb[\"options\"], 1):\n",
        "        print(f\"{i}. {opt}\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Your choice: \").strip()\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(amb[\"options\"]):\n",
        "            user_answers[amb[\"term\"]] = amb[\"options\"][int(choice)-1]\n",
        "            break\n"
      ],
      "metadata": {
        "id": "hOVYqDMufBQo",
        "outputId": "9e363efd-01be-4b38-e795-8ade3d21b1d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚ùì What is the nature of the 'sub-brand launch'?\n",
            "1. A completely new brand under the L'Or√©al corporate umbrella.\n",
            "2. A new product line or extension under an existing L'Or√©al major brand (e.g., L'Or√©al Paris, Lanc√¥me).\n",
            "3. A strategic initiative rebranding an acquired small brand.\n",
            "Your choice: 1\n",
            "\n",
            "‚ùì What is the primary purpose and expected output of this 'comprehensive case study'?\n",
            "1. A detailed strategic business plan for the sub-brand's launch.\n",
            "2. A pre-mortem analysis identifying potential risks and opportunities for the launch.\n",
            "3. A strategic document outlining key decisions and assumptions for the launch.\n",
            "4. An academic-style analysis of a hypothetical sub-brand launch.\n",
            "Your choice: 1\n",
            "\n",
            "‚ùì Which competitors should be included in the CapEx & OpEx comparison?\n",
            "1. Direct competitors within the specific high-growth segment identified for the sub-brand.\n",
            "2. Major beauty industry competitors of L'Or√©al (e.g., Est√©e Lauder, Unilever, P&G).\n",
            "3. Both direct sub-brand competitors and major beauty industry players.\n",
            "Your choice: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def enrich_brief(brief: str, clarifications: Dict[str, str]) -> str:\n",
        "    if not clarifications:\n",
        "        return brief\n",
        "\n",
        "    enriched = brief + \"\\n\\nCLARIFICATIONS:\\n\"\n",
        "    for k, v in clarifications.items():\n",
        "        enriched += f\"- {k}: {v}\\n\"\n",
        "    return enriched\n",
        "\n",
        "ENRICHED_BRIEF = enrich_brief(CASE_BRIEF, user_answers)\n",
        "print(\"‚úÖ Brief enriched\")\n"
      ],
      "metadata": {
        "id": "X1sBEimXfBTV",
        "outputId": "2df27337-4f9d-43d5-b569-c53824249cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Brief enriched\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, name: str, role: str):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "\n",
        "    def run(self, brief: str, context: str = \"\") -> str:\n",
        "        print(f\"üîÑ Running {self.name}...\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a {self.role}.\n",
        "\n",
        "Generate a professional {self.name}.\n",
        "\n",
        "Case Brief:\n",
        "{brief}\n",
        "\n",
        "Previous Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "        return llm.generate(prompt)\n"
      ],
      "metadata": {
        "id": "8PRcBmZbfBWO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agents = [\n",
        "    Agent(\"Executive Summary\", \"Senior Strategy Consultant\"),\n",
        "    Agent(\"CapEx & OpEx Analysis\", \"Financial Analyst\"),\n",
        "    Agent(\"Market Modeling\", \"Market Research Analyst\"),\n",
        "]\n",
        "\n",
        "results = {}\n",
        "context = \"\"\n",
        "\n",
        "for agent in agents:\n",
        "    output = agent.run(ENRICHED_BRIEF, context)\n",
        "    results[agent.name] = output\n",
        "    context += output[:500]\n"
      ],
      "metadata": {
        "id": "Fw1RwNRafBZG",
        "outputId": "e37c06fd-9529-471b-bf9d-d1d30cf3e6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Running Executive Summary...\n",
            "üîÑ Running CapEx & OpEx Analysis...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = f\"case_study_{time.strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for name, text in results.items():\n",
        "    filename = name.replace(\" \", \"_\") + \".md\"\n",
        "    with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "with open(os.path.join(output_dir, \"clarifications.json\"), \"w\") as f:\n",
        "    json.dump(user_answers, f, indent=2)\n",
        "\n",
        "print(\"üìÅ Saved results to:\", output_dir)\n"
      ],
      "metadata": {
        "id": "aG17kmwYfBcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSUMMARY\")\n",
        "print(\"Ambiguities detected:\", len(detected_ambiguities))\n",
        "print(\"Clarifications answered:\", len(user_answers))\n",
        "print(\"Documents generated:\", len(results))\n",
        "\n",
        "for k in results:\n",
        "    print(\"-\", k)\n"
      ],
      "metadata": {
        "id": "1lq6A4nyfBfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k-_hQXOGe3gk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "name": "CaseGenius_Enhanced_Ambiguity_Resolution.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
