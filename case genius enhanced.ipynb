{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ CaseGenius Enhanced: AI Case Study Generator with Ambiguity Resolution\n",
        "\n",
        "**New Feature:** Intelligent ambiguity detection and interactive clarification\n",
        "\n",
        "**Flow:**\n",
        "1. Enter case brief\n",
        "2. AI detects ambiguities\n",
        "3. Configure which questions to ask (max 3)\n",
        "4. Answer questions\n",
        "5. Generate comprehensive case study\n",
        "\n",
        "**Time:** 10-15 minutes | **Cost:** ~$4-5\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q anthropic>=0.40.0\n",
        "\n",
        "import anthropic\n",
        "import json\n",
        "import re\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# API Key Setup\n",
        "ANTHROPIC_API_KEY = \"\"  # ‚Üê Paste your key here\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    ANTHROPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "    print(\"‚úÖ Using API key from Colab secrets\")\n",
        "except:\n",
        "    if not ANTHROPIC_API_KEY:\n",
        "        raise ValueError(\"Please set ANTHROPIC_API_KEY\")\n",
        "    print(\"‚úÖ Using API key from code\")\n",
        "\n",
        "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
        "MODEL = \"claude-sonnet-4-20250514\"\n",
        "print(f\"ü§ñ Model: {MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Step 1: Enter Your Case Brief"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example case brief with intentional ambiguities for demo\n",
        "CASE_BRIEF = \"\"\"\n",
        "Create a comprehensive case study for a sub-brand launch.\n",
        "\n",
        "Company: L'Or√©al\n",
        "\n",
        "Analysis Required:\n",
        "1. CapEx & OpEx comparison with competitors\n",
        "2. Market modeling and sizing\n",
        "3. P&L projections\n",
        "4. Business Canvas\n",
        "5. Competitor Analysis\n",
        "6. Market gap identification\n",
        "\n",
        "The sub-brand should leverage the halo effect from L'Or√©al's existing portfolio.\n",
        "Focus on financial health and CapEx efficiency.\n",
        "\n",
        "Timeline: Launch in the next fiscal year.\n",
        "Target market: Should focus on high-growth segments.\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Case Brief Loaded\")\n",
        "print(f\"Length: {len(CASE_BRIEF)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Step 2: AI Detects Ambiguities\n",
        "\n",
        "The system will analyze your brief and identify unclear references."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AmbiguityDetector:\n",
        "    \"\"\"Detects ambiguous terms in case briefs using single LLM call\"\"\"\n",
        "    \n",
        "    def __init__(self, client: anthropic.Anthropic):\n",
        "        self.client = client\n",
        "    \n",
        "    def detect(self, brief: str) -> List[Dict]:\n",
        "        \"\"\"Single LLM call to detect all ambiguities\"\"\"\n",
        "        print(\"\\nüîç Analyzing brief for ambiguities...\")\n",
        "        \n",
        "        prompt = f\"\"\"Analyze this case study brief and identify ambiguous terms or references that need clarification.\n",
        "\n",
        "Case Brief:\n",
        "{brief}\n",
        "\n",
        "Identify ambiguities in these categories:\n",
        "1. TIME REFERENCES: \"this year\", \"next quarter\", \"recently\" (which specific date/period?)\n",
        "2. VAGUE DESCRIPTORS: \"high-growth\", \"major competitors\", \"key markets\" (which specific ones?)\n",
        "3. UNDEFINED SCOPE: \"sub-brand\" without category, \"target market\" without demographics\n",
        "4. IMPLICIT ASSUMPTIONS: \"fiscal year\" (which company's fiscal calendar?)\n",
        "\n",
        "For each ambiguity found, provide:\n",
        "- term: The ambiguous phrase\n",
        "- category: TIME/SCOPE/DESCRIPTOR/ASSUMPTION\n",
        "- question: Clear question to resolve it\n",
        "- options: 3-4 multiple choice options\n",
        "- importance: HIGH/MEDIUM/LOW (how critical is this to the analysis?)\n",
        "\n",
        "Return ONLY a JSON array. Example:\n",
        "[\n",
        "  {{\n",
        "    \"term\": \"next fiscal year\",\n",
        "    \"category\": \"TIME\",\n",
        "    \"question\": \"Which fiscal year should the launch target?\",\n",
        "    \"options\": [\"FY 2026 (Jan-Dec 2026)\", \"FY 2027 (Jan-Dec 2027)\", \"L'Or√©al FY 2026 (Jul 2025-Jun 2026)\"],\n",
        "    \"importance\": \"HIGH\"\n",
        "  }}\n",
        "]\n",
        "\n",
        "If no ambiguities, return [].\"\"\"\n",
        "        \n",
        "        try:\n",
        "            response = self.client.messages.create(\n",
        "                model=MODEL,\n",
        "                max_tokens=4000,\n",
        "                temperature=0,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "            )\n",
        "            \n",
        "            content = response.content[0].text\n",
        "            \n",
        "            # Extract JSON (remove markdown fences if present)\n",
        "            json_match = re.search(r'\\[.*\\]', content, re.DOTALL)\n",
        "            if json_match:\n",
        "                ambiguities = json.loads(json_match.group())\n",
        "                print(f\"   ‚úÖ Found {len(ambiguities)} potential ambiguities\")\n",
        "                return ambiguities\n",
        "            else:\n",
        "                print(\"   ‚úÖ No ambiguities detected\")\n",
        "                return []\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ö†Ô∏è Detection failed: {e}\")\n",
        "            return []\n",
        "\n",
        "# Run detection\n",
        "detector = AmbiguityDetector(client)\n",
        "detected_ambiguities = detector.detect(CASE_BRIEF)\n",
        "\n",
        "# Display results\n",
        "if detected_ambiguities:\n",
        "    print(\"\\nüìä Detected Ambiguities:\\n\")\n",
        "    for i, amb in enumerate(detected_ambiguities, 1):\n",
        "        print(f\"{i}. [{amb['importance']}] {amb['term']}\")\n",
        "        print(f\"   Category: {amb['category']}\")\n",
        "        print(f\"   Question: {amb['question']}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"\\n‚úÖ No ambiguities detected. Proceeding with analysis...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Step 3: Configure Which Questions to Ask\n",
        "\n",
        "**Max 3 questions** - Select the most important ones to resolve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CONFIGURABLE: Choose which ambiguities to ask about\n",
        "# Edit the indices below (1-based indexing)\n",
        "\n",
        "if detected_ambiguities:\n",
        "    # Default: Ask about HIGH importance items, up to 3\n",
        "    high_importance = [i for i, amb in enumerate(detected_ambiguities) if amb['importance'] == 'HIGH']\n",
        "    \n",
        "    # Auto-select top 3 high-importance, or all if fewer\n",
        "    QUESTIONS_TO_ASK = high_importance[:3]\n",
        "    \n",
        "    print(\"üéõÔ∏è Configuration: Questions to Ask\\n\")\n",
        "    print(\"AUTO-SELECTED (based on importance):\")\n",
        "    for idx in QUESTIONS_TO_ASK:\n",
        "        amb = detected_ambiguities[idx]\n",
        "        print(f\"  [{idx+1}] {amb['term']} - {amb['importance']}\")\n",
        "    \n",
        "    print(\"\\nüí° To customize:\")\n",
        "    print(\"   Edit QUESTIONS_TO_ASK = [0, 2, 4] (change indices)\")\n",
        "    print(\"   Then re-run this cell\")\n",
        "    \n",
        "else:\n",
        "    QUESTIONS_TO_ASK = []\n",
        "    print(\"No questions to configure.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí¨ Step 4: Answer Clarifying Questions\n",
        "\n",
        "**Instructions:** For each question below, enter the number of your choice (e.g., 1, 2, or 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Q&A\n",
        "user_answers = {}\n",
        "\n",
        "if QUESTIONS_TO_ASK:\n",
        "    print(\"=\"*60)\n",
        "    print(\"üìã CLARIFYING QUESTIONS\")\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "    \n",
        "    for idx in QUESTIONS_TO_ASK:\n",
        "        amb = detected_ambiguities[idx]\n",
        "        \n",
        "        print(f\"\\n‚ùì Question {idx+1}: {amb['question']}\")\n",
        "        print(f\"   (Ambiguous term: '{amb['term']}')\\n\")\n",
        "        \n",
        "        for i, option in enumerate(amb['options'], 1):\n",
        "            print(f\"   {i}. {option}\")\n",
        "        \n",
        "        # Text input (pause execution until answered)\n",
        "        while True:\n",
        "            answer_num = input(f\"\\n   Your choice (1-{len(amb['options'])}): \").strip()\n",
        "            try:\n",
        "                answer_num = int(answer_num)\n",
        "                if 1 <= answer_num <= len(amb['options']):\n",
        "                    user_answers[amb['term']] = amb['options'][answer_num - 1]\n",
        "                    print(f\"   ‚úÖ Recorded: {amb['options'][answer_num - 1]}\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"   ‚ùå Please enter a number between 1 and {len(amb['options'])}\")\n",
        "            except ValueError:\n",
        "                print(\"   ‚ùå Please enter a valid number\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ ALL QUESTIONS ANSWERED\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nYour Clarifications:\")\n",
        "    for term, answer in user_answers.items():\n",
        "        print(f\"  ‚Ä¢ {term} ‚Üí {answer}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚úÖ No questions to answer. Proceeding with original brief.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Step 5: Enrich Brief with Clarifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def enrich_brief(original_brief: str, clarifications: Dict[str, str]) -> str:\n",
        "    \"\"\"Add clarifications to brief as structured context\"\"\"\n",
        "    \n",
        "    if not clarifications:\n",
        "        return original_brief\n",
        "    \n",
        "    enriched = original_brief + \"\\n\\n\" + \"=\"*60 + \"\\n\"\n",
        "    enriched += \"CLARIFICATIONS (resolved ambiguities):\\n\\n\"\n",
        "    \n",
        "    for term, resolution in clarifications.items():\n",
        "        enriched += f\"‚Ä¢ '{term}' means: {resolution}\\n\"\n",
        "    \n",
        "    enriched += \"=\"*60\n",
        "    \n",
        "    return enriched\n",
        "\n",
        "# Create enriched brief\n",
        "ENRICHED_BRIEF = enrich_brief(CASE_BRIEF, user_answers)\n",
        "\n",
        "print(\"üìÑ Enriched Brief Preview:\\n\")\n",
        "print(ENRICHED_BRIEF[:500] + \"...\\n\")\n",
        "print(f\"‚úÖ Brief enriched with {len(user_answers)} clarifications\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Step 6: Generate Case Study\n",
        "\n",
        "Now running the full 6-agent analysis with clarified context..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cost tracking\n",
        "class CostGuard:\n",
        "    def __init__(self, max_cost_usd=10):\n",
        "        self.total_input_tokens = 0\n",
        "        self.total_output_tokens = 0\n",
        "        self.max_cost = max_cost_usd\n",
        "        self.input_price = 3 / 1_000_000\n",
        "        self.output_price = 15 / 1_000_000\n",
        "    \n",
        "    def track(self, usage):\n",
        "        self.total_input_tokens += usage.input_tokens\n",
        "        self.total_output_tokens += usage.output_tokens\n",
        "        cost = (self.total_input_tokens * self.input_price + \n",
        "                self.total_output_tokens * self.output_price)\n",
        "        if cost > self.max_cost:\n",
        "            raise Exception(f\"Budget exceeded: ${cost:.2f}\")\n",
        "        return cost\n",
        "    \n",
        "    def report(self):\n",
        "        cost = (self.total_input_tokens * self.input_price + \n",
        "                self.total_output_tokens * self.output_price)\n",
        "        print(f\"\\nüí∞ Total API Cost: ${cost:.2f}\")\n",
        "        print(f\"   Input tokens: {self.total_input_tokens:,}\")\n",
        "        print(f\"   Output tokens: {self.total_output_tokens:,}\")\n",
        "        return cost\n",
        "\n",
        "cost_guard = CostGuard(max_cost_usd=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simplified agent for demo\n",
        "class SimplifiedAgent:\n",
        "    def __init__(self, name: str, role: str):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "    \n",
        "    def run(self, brief: str, context: Optional[str] = None) -> str:\n",
        "        print(f\"\\nüîÑ {self.name}...\")\n",
        "        \n",
        "        system = f\"\"\"You are a {self.role} in management consulting.\n",
        "Produce client-ready analysis with:\n",
        "- Data-driven insights (cite sources)\n",
        "- Structured frameworks\n",
        "- Financial rigor\n",
        "- Clear communication\n",
        "\n",
        "CRITICAL: Pay attention to any CLARIFICATIONS in the brief - these resolve ambiguities.\"\"\"\n",
        "        \n",
        "        user_prompt = f\"\"\"Create {self.name} for this case.\n",
        "\n",
        "Case Brief:\n",
        "{brief}\n",
        "\n",
        "{f'Prior Analysis Context: {context[:1000]}...' if context else ''}\n",
        "\n",
        "Generate comprehensive, professional analysis (2-3 pages markdown).\"\"\"\n",
        "        \n",
        "        try:\n",
        "            start = time.time()\n",
        "            response = client.messages.create(\n",
        "                model=MODEL,\n",
        "                max_tokens=8000,\n",
        "                system=system,\n",
        "                messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
        "                tools=[{\"type\": \"web_search_20250305\", \"name\": \"web_search\"}]\n",
        "            )\n",
        "            \n",
        "            # Extract text\n",
        "            text = \"\".join([b.text for b in response.content if hasattr(b, 'text')])\n",
        "            \n",
        "            cost = cost_guard.track(response.usage)\n",
        "            print(f\"   ‚úÖ Done in {time.time()-start:.1f}s (${cost:.2f} total)\")\n",
        "            \n",
        "            return text\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error: {e}\")\n",
        "            return f\"# {self.name}\\n\\n[Generation failed]\"\n",
        "\n",
        "print(\"‚úÖ Agent system ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run analysis\n",
        "print(\"=\"*60)\n",
        "print(\"üöÄ GENERATING CASE STUDY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Only generate 3 key documents for demo (cost control)\n",
        "agents = [\n",
        "    SimplifiedAgent(\"Executive Summary\", \"Senior Strategy Consultant\"),\n",
        "    SimplifiedAgent(\"CapEx & OpEx Analysis\", \"CFO-level Financial Analyst\"),\n",
        "    SimplifiedAgent(\"Market Modeling\", \"Market Research Analyst\")\n",
        "]\n",
        "\n",
        "context = \"\"\n",
        "for agent in agents:\n",
        "    output = agent.run(ENRICHED_BRIEF, context)\n",
        "    results[agent.name] = output\n",
        "    context += f\"\\n\\n{agent.name}:\\n{output[:500]}...\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ GENERATION COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "cost_guard.report()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Step 7: Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "output_dir = f\"case_study_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save documents\n",
        "file_map = {\n",
        "    'Executive Summary': '01_Executive_Summary.md',\n",
        "    'CapEx & OpEx Analysis': '02_CapEx_Analysis.md',\n",
        "    'Market Modeling': '03_Market_Modeling.md'\n",
        "}\n",
        "\n",
        "for name, filename in file_map.items():\n",
        "    filepath = os.path.join(output_dir, filename)\n",
        "    with open(filepath, 'w', encoding='utf-8') as f:\n",
        "        f.write(results[name])\n",
        "    print(f\"‚úÖ Saved: {filename}\")\n",
        "\n",
        "# Save clarifications log\n",
        "clarifications_log = {\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'detected_ambiguities': detected_ambiguities,\n",
        "    'questions_asked': [detected_ambiguities[i] for i in QUESTIONS_TO_ASK],\n",
        "    'user_answers': user_answers\n",
        "}\n",
        "\n",
        "with open(os.path.join(output_dir, 'clarifications.json'), 'w') as f:\n",
        "    json.dump(clarifications_log, f, indent=2)\n",
        "\n",
        "print(f\"\\nüìÅ All files saved to: {output_dir}/\")\n",
        "print(\"\\nüì• Download from Files panel (left sidebar)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Demo Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä AMBIGUITY RESOLUTION DEMO SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n1Ô∏è‚É£ Ambiguities Detected: {len(detected_ambiguities)}\")\n",
        "if detected_ambiguities:\n",
        "    for amb in detected_ambiguities:\n",
        "        print(f\"   ‚Ä¢ {amb['term']} ({amb['importance']})\")\n",
        "\n",
        "print(f\"\\n2Ô∏è‚É£ Questions Asked: {len(QUESTIONS_TO_ASK)}\")\n",
        "for term, answer in user_answers.items():\n",
        "    print(f\"   ‚Ä¢ {term}\\n     ‚Üí {answer}\")\n",
        "\n",
        "print(f\"\\n3Ô∏è‚É£ Documents Generated: {len(results)}\")\n",
        "for name in results.keys():\n",
        "    word_count = len(results[name].split())\n",
        "    print(f\"   ‚Ä¢ {name}: {word_count:,} words\")\n",
        "\n",
        "final_cost = cost_guard.report()\n",
        "\n",
        "print(\"\\n‚ú® Key Innovation:\")\n",
        "print(\"   Human-in-the-loop clarification BEFORE expensive analysis\")\n",
        "print(\"   Prevents wasted API calls on ambiguous briefs\")\n",
        "print(\"   Ensures analysis matches PM's actual intent\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ What Just Happened?\n",
        "\n",
        "### Enhanced Workflow:\n",
        "\n",
        "1. ‚úÖ **Detected ambiguities** in your brief (single LLM call)\n",
        "2. ‚úÖ **Configured questions** (you chose top 3 by importance)\n",
        "3. ‚úÖ **Answered clarifications** (interactive multiple choice)\n",
        "4. ‚úÖ **Enriched brief** with your answers\n",
        "5. ‚úÖ **Generated analysis** using clarified context\n",
        "\n",
        "### Why This Matters:\n",
        "\n",
        "**Before (Original CaseGenius):**\n",
        "- PM submits brief with \"next fiscal year\"\n",
        "- AI guesses which year (might be wrong)\n",
        "- PM wastes time fixing incorrect assumptions\n",
        "\n",
        "**After (Enhanced Version):**\n",
        "- AI detects \"next fiscal year\" is ambiguous\n",
        "- Asks: \"Which fiscal year? 2026, 2027, or L'Or√©al FY 2026?\"\n",
        "- PM clarifies once\n",
        "- All 6 documents use correct year\n",
        "\n",
        "### Cost Efficiency:\n",
        "\n",
        "- **Ambiguity detection:** 1 LLM call (~$0.05)\n",
        "- **Prevents:** Re-running entire analysis ($4) due to wrong assumptions\n",
        "- **ROI:** 80:1 cost savings when avoiding rework\n",
        "\n",
        "---\n",
        "\n",
        "## üîÑ Try It Again\n",
        "\n",
        "Want to test with your own case brief?\n",
        "\n",
        "1. Edit the `CASE_BRIEF` cell at the top\n",
        "2. Run all cells again\n",
        "3. Answer the new clarifying questions\n",
        "4. Get a tailored case study\n",
        "\n",
        "---\n",
        "\n",
        "*Generated by **CaseGenius Enhanced** - Ambiguity-Aware AI Assistant*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "name": "CaseGenius_Enhanced_Ambiguity_Resolution.ipynb"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
